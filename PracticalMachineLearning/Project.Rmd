---
title: "Human Activity Recognition Project"
author: "Tell Bennett"
output: html_document
---



Synopsis
--------




Data Processing
---------------

```{r options, echo = FALSE}
options(dplyr.max_print = 10)
options(dplyr.min_print =  5)
```

  

1) Load R packages

```{r loadpackages, echo = TRUE, results="hide", message=FALSE}
library(MASS)
library(dplyr)
library(caret)
library(readr)
library(magrittr)

library(htmlTable)
```

  
  
  

2) Load the raw data

```{r dataload, cache=TRUE}
## Download the train data 
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(trainurl, destfile = "data/pml-training.csv")

## Document the download time
traindownloadtime <- date()
traindownloadtime



## Download the train data 
testurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(testurl, destfile = "data/pml-testing.csv")

## Document the download time
testdownloadtime <- date()
testdownloadtime

```

  
  
  

3) Read the data into R

```{r dataread, cache=TRUE, message = FALSE, warning = FALSE}
training <- read_csv("data/pml-training.csv")
testing <- read_csv("data/pml-testing.csv")
```

  
  
  

4) Exploring the raw data
```{r explore1, cache = TRUE, echo = FALSE, results="hide", message=FALSE}
dim(training)
dim(testing)

glimpse(training)
names(training)
head(training)
tail(training)
summary(training)  ### a number of the variables have substantial missing data
```



5) Remove columns with overwhelming amounts of missing data
```{r select1, echo = FALSE, results = "hide", message = FALSE}

### turning empty character strings into NA
training[training==""] <- NA 
testing[testing==""] <- NA 

### dropping the columns with lots (more than 19000/19622 total rows) of missing data
training <- training[, sapply(training, function(x) sum(is.na(x))) < 19000]
testing <- testing[, sapply(testing, function(x) sum(is.na(x))) < 10]

### amount of missing data in remaining columns - max 1 missing
sapply(training, function(x) sum(is.na(x)))
sapply(testing, function(x) sum(is.na(x)))

### explore data again
glimpse(training)
glimpse(testing)
```

  
  
  

6) Cleaning userid and outcome
```{r clean1, cache=TRUE}
training %<>%
     mutate(
        class = factor(classe),
        user = factor(user_name))

### Examining execution class by user
table(training$class,training$user)

```
Overall, the classes are reasonably balanced, so overall accuracy is likely an acceptable
performance measure for the prediction model.
  
  
  
  
7) Exploring time variables
```{r time1, cache=TRUE}

training %>%
     dplyr::select(user, contains("cvtd")) %>%
     group_by(user) %>%
     table(.)
 
# htmlTable(byevtype2,
#           rnames = FALSE,
#          # header = c("Event Type", "Mean Property Damage ($)", "Mean Crop Damage ($)"),
#           caption = "<a name=table03></a> <b> Table 3 </b> Damage per Storm Event Type ($millions)",
#           align = "llll",
#           align.header = "llll")
```
The training data were generated by observing 6 individuals lift the weight. Each person
was observed only once, and each person's observations were taken over 2-3 minutes on one day.
Therefore, I'll consider each person's data to have come from a single event, and will
not consider time variables as potential predictors. 

Because we do not have data about the individuals("users"), it will not be useful
to include "user" ID as a predictor, so I drop that variable.


8) Removing unnecessary time variables and user ID
```{r select2, cache=TRUE}
training %<>%
     dplyr::select(-c(1:7),-classe,-user,-user_name)

testing %<>%
     dplyr::select(-c(1:7),-problem_id)
```



9) Pairs plots
```{r pairsplots, cache=TRUE}

# ### Belt variables
# training %>%
#      select(contains("belt"), class) %>%
#      pairs(.)
# 
# ### Arm variables
# training %>%
#      select(contains("_arm"), class) %>%
#      pairs(.)
# 
# ### Dumbbell variables
# training %>%
#      select(contains("dumbbell"), class) %>%
#      pairs(.)
# 
# ### Forearm variables
# training %>%
#      select(contains("forearm"), class) %>%
#      pairs(.)
```



10) Looking for correlation among predictors and trimming predictors
```{r corr, cache = TRUE}

M <- training %>%
     dplyr::select(-class) %>%
     cor(.) %>%
     abs(.)

diag(M) <- 0

which(M > 0.9,arr.ind=T)

training %<>%
     dplyr::select(-accel_belt_y, -accel_belt_z, -gyros_arm_y, -gyros_forearm_z)

testing %<>%
     dplyr::select(-accel_belt_y, -accel_belt_z, -gyros_arm_y, -gyros_forearm_z)
```
Many predictors are highly correlated (r > 0.9). To simply the prediction process and improve interpretability, 
In particular, `total_accel_belt` is highly correlated with `accel_belt_y` and `accel_belt_z`, but not with `accel_belt_x`, so I excluded the `y` and `z` variables and kept `total` and `x`. `gyros_arm_x` and `gyros_arm_y` are highly correlated, so I kept `x`. `gyros_dumbbell_x` and `gyros_dumbbell_z` and `gyros_forearm_z` were all highly correlated, so I kept
only `gyros_forearm_z`.

  
11) Pre-processing
```{r preprocess1, cache = TRUE}
# 
# preobj <- training %<>%
#      preProcess(method = c("center", "scale"))  ### variables that aren't numeric are ignored (class is a factors)



```
  
  
12) Testing LDA and Naive Bayes models
```{r glm1, cache=TRUE}

ldafit <- train(class ~ ., data = training, preProcess = "scale", method="lda")
plda <- predict(ldafit, testing)

nbfit <- train(class ~ ., data = training, preProcess = "scale", method="nb")
pnb <- predict(nbfit, testing)

table(plda,pnb)

```

13) Testing tree models
```{r tree1, cache = TRUE}

treefit <- train(x = training[,-49], y = training$class, 
               preProcess = "scale", 
               method="rpart")

print(treefit$finalModel)

plot(treefit$finalModel, uniform=TRUE, 
      main="Classification Tree")
text(treefit$finalModel, use.n=TRUE, all=TRUE, cex=.8)

predict(treefit,newdata=testing)

```

14) Testing RF models
```{r rf1, cache = TRUE}

# 
# rffit <- train(x = training[,-49], y = training$class, 
#                preProcess = c("center", "scale"), 
#                method="rf",
#                tuneLength  = 5,
#                trControl = trainControl(number = 1))

yesprint(modFit$finalModel)



```


